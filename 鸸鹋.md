
很抱歉这么晚才发过来,您可以看一下代码:[ermiao_test](https://github.com/bugkiwi/ermiao_test)

目前完成数组A的开发和测试,B只写完程序,测试还没写.

#####使用到的第三方py库:

	* sqlachemy
	* redis

#####使用到的数据库,之前没接触过MongoDB:(

	* mysql
	* redis
	mysql只是存储了一点基础User-Entry数据,可以方便换乘MongoDB,主要计算结果都在redis中
	
#####目前代码思路:

	针对权重数组A:
		用到redis的两种数据结构,一个是带有有效期的key,另外一个是有序集合;
		通过redis.setex为每一个Entry设置一个24小时过期时间,当用户'喜欢'或'评论'时候,更新这个Entry的value,存储其时间,而在有序集合"WEIGHT_A"中,存储每个member(对应Entry的id)的权重;
		
		当查询时候,通过有续集和可以很方便的获取到前100名对应的Entry,然后再通过redis.mget获取对应的更新时间.这样子就能得到一个Enrty[id,weight,update_time]数组
	
	针对权重数组B:
		采用事件驱动而非每次计算,这样子能讲压力分布出去;
		用到数据结构,带有有效期的key,一个有序集合;
		当用户登陆时候,通过查询mysql的Entry表,获取24小时之前的此用户发布的所有Entry,然后将其redis.setex设置48小时过期,将权重存储于key=Weight_B的有序集合内;此时用到一个小技巧就是此Entry的作者登陆时候,若之前Entry不存在,则权重设置为int(time.time()).后面其他用户访问,留言的权重为2*10^11,喜欢的权重1*2^11.
		然后如上,获取有续集合中score大于 2^11+time.time()-3600*24 的即可.

	个人觉得对于点赞,排序,这种不算重要,但是又高访问的数据,用redis比较合适(好吧,那是因为我不懂MongoDB)
	
#####缺点:

* 随着数据增加,显然有序集合取出数据难度将要增加;解决方案:每晚上跑个crontab,剔除掉有序集合中的冗余数据
* 遇见高并发,目前的代码记权重应该会有问题,但是这个影响不大,毕竟只是展示数据;当然可以将需要多步操作redis的python代码写成lua脚本,register_script后再调用,就可以解决这个并发问题.

我不确定当鸸鹋数据量大到一定程度时候,每5分钟第一个访问timeline时候,是否会有延迟,如果速度明显降低,个人也比较倾向于利用crontab,提前计算,由后台定时任务自己触发更新timeline然后交给客户端访问;


#####关于这个邮件中的两个问题:

* 单一用户很容易用低质量的内容刷屏
	
	我不是很明白"低质量"在此处的含义,如果是一些不文明用语或者毫无意义的字符,那么只能通过类似邮件过滤之类的.而对于"不错","好漂亮","好萌"这样之类的回复,我倒是觉得不算低质量刷屏,我看了鸸鹋的几个页面,回复都不多,觉得低质量刷屏也是很好的.当用户回复达到一定量的时候,可以用折叠/赞 等产品手段来引导用户往高质量上走.

* 稍早时间发布的内容难以被挖掘

	倒是可以将过往(一个月之前)的创建Entry计算出权重后存表,然后按照日期路由到部分数据,比如今天是12号,就可以路由到往月的12日,将权重较高的几个Entry随机取出推到用户前台,这样子既不会太乏味,也可以将以前的优秀Entry推送过来,然后大家再计算`评论`,`喜欢`动作后的权重归表~~
	

大概就这些了,MongoDB虽没学过,但是很感兴趣,毕竟学新东西是件令人高兴的事情!

**如果不符合您的要求,亦恳请您指出我的不足.谢谢您看了这么:)**